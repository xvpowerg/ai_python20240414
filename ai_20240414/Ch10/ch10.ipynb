{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['2023/5/28', '2023/5/29', '2023/5/30', '2023/5/31', '2023/6/1',\n",
      "       '2023/6/2', '2023/6/3', '2023/6/4', '2023/6/5', '2023/6/6',\n",
      "       ...\n",
      "       '2023/12/4', '2023/12/5', '2023/12/6', '2023/12/7', '2023/12/8',\n",
      "       '2023/12/9', '2023/12/10', '2023/12/11', '2023/12/12', '2023/12/13'],\n",
      "      dtype='object', name='Date', length=200)\n",
      "<class 'str'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "顯示資料類型\n",
      "num    int64\n",
      "dtype: object\n",
      "            num\n",
      "Date           \n",
      "2023/5/28     1\n",
      "2023/5/29     2\n",
      "2023/5/30     3\n",
      "2023/5/31     4\n",
      "2023/6/1      5\n",
      "...         ...\n",
      "2023/12/9   196\n",
      "2023/12/10  197\n",
      "2023/12/11  198\n",
      "2023/12/12  199\n",
      "2023/12/13  200\n",
      "\n",
      "[200 rows x 1 columns]\n",
      "計算每個月資料總和，為什麼異常?\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(se2)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m計算每個月資料總和，為什麼異常?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m se2M\u001b[38;5;241m=\u001b[39mse2\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(se2M)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:9439\u001b[0m, in \u001b[0;36mNDFrame.resample\u001b[1;34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001b[0m\n\u001b[0;32m   9436\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   9437\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 9439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_resampler(\n\u001b[0;32m   9440\u001b[0m     cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries | DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   9441\u001b[0m     freq\u001b[38;5;241m=\u001b[39mrule,\n\u001b[0;32m   9442\u001b[0m     label\u001b[38;5;241m=\u001b[39mlabel,\n\u001b[0;32m   9443\u001b[0m     closed\u001b[38;5;241m=\u001b[39mclosed,\n\u001b[0;32m   9444\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   9445\u001b[0m     kind\u001b[38;5;241m=\u001b[39mkind,\n\u001b[0;32m   9446\u001b[0m     convention\u001b[38;5;241m=\u001b[39mconvention,\n\u001b[0;32m   9447\u001b[0m     key\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m   9448\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   9449\u001b[0m     origin\u001b[38;5;241m=\u001b[39morigin,\n\u001b[0;32m   9450\u001b[0m     offset\u001b[38;5;241m=\u001b[39moffset,\n\u001b[0;32m   9451\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[0;32m   9452\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\resample.py:1970\u001b[0m, in \u001b[0;36mget_resampler\u001b[1;34m(obj, kind, **kwds)\u001b[0m\n\u001b[0;32m   1966\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1967\u001b[0m \u001b[38;5;124;03mCreate a TimeGrouper and return our resampler.\u001b[39;00m\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1969\u001b[0m tg \u001b[38;5;241m=\u001b[39m TimeGrouper(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 1970\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tg\u001b[38;5;241m.\u001b[39m_get_resampler(obj, kind\u001b[38;5;241m=\u001b[39mkind)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\resample.py:2160\u001b[0m, in \u001b[0;36mTimeGrouper._get_resampler\u001b[1;34m(self, obj, kind)\u001b[0m\n\u001b[0;32m   2151\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ax, TimedeltaIndex):\n\u001b[0;32m   2152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TimedeltaIndexResampler(\n\u001b[0;32m   2153\u001b[0m         obj,\n\u001b[0;32m   2154\u001b[0m         timegrouper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2157\u001b[0m         gpr_index\u001b[38;5;241m=\u001b[39max,\n\u001b[0;32m   2158\u001b[0m     )\n\u001b[1;32m-> 2160\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2161\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly valid with DatetimeIndex, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2162\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimedeltaIndex or PeriodIndex, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2163\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got an instance of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(ax)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2164\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from  datetime import  date\n",
    "import  numpy as np\n",
    "se2=pd.read_csv(\n",
    "    'se2.csv',\n",
    "    index_col='Date',names=['Date','num'])\n",
    "print(se2.index)\n",
    "print(type(se2.index[0]))\n",
    "print(se2.__class__)\n",
    "print('顯示資料類型')\n",
    "print(se2.dtypes)\n",
    "print(se2)\n",
    "print('計算每個月資料總和，為什麼異常?')\n",
    "se2M=se2.resample('M').sum()\n",
    "print(se2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "顯示索引1\n",
      "RangeIndex(start=0, stop=200, step=1)\n",
      "顯示資料類型1\n",
      "Date    object\n",
      "num      int64\n",
      "dtype: object\n",
      "           Date  num\n",
      "0     2023/5/28    1\n",
      "1     2023/5/29    2\n",
      "2     2023/5/30    3\n",
      "3     2023/5/31    4\n",
      "4      2023/6/1    5\n",
      "..          ...  ...\n",
      "195   2023/12/9  196\n",
      "196  2023/12/10  197\n",
      "197  2023/12/11  198\n",
      "198  2023/12/12  199\n",
      "199  2023/12/13  200\n",
      "\n",
      "[200 rows x 2 columns]\n",
      "顯示資料類型2\n",
      "Date    datetime64[ns]\n",
      "num              int64\n",
      "dtype: object\n",
      "顯示索引2\n",
      "DatetimeIndex(['2023-05-28', '2023-05-29', '2023-05-30', '2023-05-31',\n",
      "               '2023-06-01', '2023-06-02', '2023-06-03', '2023-06-04',\n",
      "               '2023-06-05', '2023-06-06',\n",
      "               ...\n",
      "               '2023-12-04', '2023-12-05', '2023-12-06', '2023-12-07',\n",
      "               '2023-12-08', '2023-12-09', '2023-12-10', '2023-12-11',\n",
      "               '2023-12-12', '2023-12-13'],\n",
      "              dtype='datetime64[ns]', name='Date', length=200, freq=None)\n",
      "            num\n",
      "Date           \n",
      "2023-05-28    1\n",
      "2023-05-29    2\n",
      "2023-05-30    3\n",
      "2023-05-31    4\n",
      "2023-06-01    5\n",
      "...         ...\n",
      "2023-12-09  196\n",
      "2023-12-10  197\n",
      "2023-12-11  198\n",
      "2023-12-12  199\n",
      "2023-12-13  200\n",
      "\n",
      "[200 rows x 1 columns]\n",
      "計算每個月資料總和\n",
      "             num\n",
      "Date            \n",
      "2023-05-31    10\n",
      "2023-06-30   585\n",
      "2023-07-31  1550\n",
      "2023-08-31  2511\n",
      "2023-09-30  3345\n",
      "2023-10-31  4402\n",
      "2023-11-30  5175\n",
      "2023-12-31  2522\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from  datetime import  date\n",
    "import  numpy as np\n",
    "se2=pd.read_csv(\n",
    "    './se2.csv',\n",
    "    names=['Date','num'])\n",
    "print('顯示索引1')\n",
    "print(se2.index)\n",
    "print('顯示資料類型1')\n",
    "print(se2.dtypes)\n",
    "print(se2)\n",
    "se2['Date']=pd.to_datetime(se2['Date'])\n",
    "print('顯示資料類型2')\n",
    "print(se2.dtypes)\n",
    "se2.set_index('Date',inplace=True)#修改目前se2\n",
    "print('顯示索引2')\n",
    "print(se2.index)\n",
    "print(se2)\n",
    "print('計算每個月資料總和')\n",
    "se2M=se2.resample('M').sum()\n",
    "print(se2M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 判斷遺失值產生原因\n",
    "+ 有些資訊是暫時無法讀取。\n",
    "+ 有些資訊是被遺漏。\n",
    "+ 有些對象的某些屬性特徵是不存在。\n",
    "+ 有些資訊被認為不重要。\n",
    "+ 操作這些資訊的代價太大而被遺棄。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A     B     C    D\n",
      "0   1.0   2.0   3.5  4.0\n",
      "1   5.5  34.0   3.4  NaN\n",
      "2  10.0   NaN  11.5  8.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import  numpy as np\n",
    "from io import  StringIO\n",
    "csv_data='''\n",
    "A,B,C,D\n",
    "1.0,2.0,3.5,4\n",
    "5.5,34,3.4\n",
    "10,,11.5,8.5\n",
    "'''\n",
    "data1=pd.read_csv(StringIO(csv_data))\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "將資料轉換為html，以便查看\n",
      "年度                     0\n",
      "行業別                    0\n",
      "經常性薪資-薪資               0\n",
      "經常性薪資-女/男              0\n",
      "專業人員-薪資                2\n",
      "專業人員-女/男              14\n",
      "技術員及助理專業人員-薪資          2\n",
      "技術員及助理專業人員-女/男         6\n",
      "事務支援人員-薪資              0\n",
      "事務支援人員-女/男             1\n",
      "服務及銷售工作人員-薪資          16\n",
      "服務及銷售工作人員-女/男         25\n",
      "技藝_機械設備操作及組裝人員-薪資     13\n",
      "技藝_機械設備操作及組裝人員-女/男    22\n",
      "基層技術工及勞力工-薪資          17\n",
      "基層技術工及勞力工-女/男         33\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas  as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('./2017.csv',encoding='utf-8-sig')\n",
    "#print(df)\n",
    "print('將資料轉換為html，以便查看')\n",
    "html=df.to_html()\n",
    "with open('work1.html','w',encoding='utf-8') as file:\n",
    "    file.writelines('<meta charset=\"utf-8\">\\n')\n",
    "    file.write(html)\n",
    "df=df.replace('—',np.NaN)\n",
    "df=df.replace('…',np.NaN)\n",
    "html=df.to_html()\n",
    "with open('work2.html','w',encoding='utf-8') as file:\n",
    "    file.writelines('<meta charset=\"utf-8\">\\n')\n",
    "    file.write(html)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B     C    D\n",
      "0   1.0  2.0     x    4\n",
      "1   5.5   34   3.4    x\n",
      "2  10.0    x  11.5  8.5\n",
      "A    3\n",
      "B    3\n",
      "C    3\n",
      "D    3\n",
      "dtype: int64\n",
      "A    3\n",
      "B    2\n",
      "C    2\n",
      "D    2\n",
      "dtype: int64\n",
      "A    False\n",
      "B     True\n",
      "C     True\n",
      "D     True\n",
      "dtype: bool\n",
      "A    0\n",
      "B    1\n",
      "C    1\n",
      "D    1\n",
      "dtype: int64\n",
      "======================================================================\n",
      "      A    B     C    D\n",
      "0   1.0  2.0   NaN    4\n",
      "1   5.5   34   3.4  NaN\n",
      "2  10.0  NaN  11.5  8.5\n",
      "type: <class 'str'>\n",
      "======================\n",
      "mean:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m======================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(data3\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11335\u001b[0m, in \u001b[0;36mDataFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11327\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m  11328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11329\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11333\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11334\u001b[0m ):\n\u001b[1;32m> 11335\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mmean(axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m  11336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[0;32m  11337\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11992\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11985\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11986\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11987\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11990\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11991\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 11992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  11994\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11949\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11945\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  11947\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  11950\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  11951\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11204\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  11200\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m  11202\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  11203\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 11204\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreduce(blk_func)\n\u001b[0;32m  11205\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res, axes\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  11206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1459\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1457\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1458\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1459\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mreduce(func)\n\u001b[0;32m   1460\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1462\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:377\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 377\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    380\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11136\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  11134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([result])\n\u001b[0;32m  11135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 11136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:719\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    716\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m    720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import  numpy as np\n",
    "from io import  StringIO\n",
    "csv_data='''\n",
    "A,B,C,D\n",
    "1.0,2.0,x,4\n",
    "5.5,34,3.4,x\n",
    "10,x,11.5,8.5\n",
    "'''\n",
    "data3=pd.read_csv(StringIO(csv_data))\n",
    "print(data3)\n",
    "\n",
    "print(data3.count())\n",
    "data3=data3.replace('x',np.NaN)\n",
    "print(data3.count())\n",
    "\n",
    "print(data3.isnull().any())#重要\n",
    "print(data3.isnull().sum())#重要\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(data3)\n",
    "print(\"type:\",type(data3.loc[0,\"B\"]) )\n",
    "print(\"======================\")\n",
    "print(\"mean:\")\n",
    "print(data3.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B     C    D\n",
      "0   1.0  2.0     x    4\n",
      "1   5.5   34   3.4    x\n",
      "2  10.0    x  11.5  8.5\n",
      "      A    B     C    D\n",
      "0   1.0  2.0   NaN    4\n",
      "1   5.5   34   3.4  NaN\n",
      "2  10.0  NaN  11.5  8.5\n",
      "========================================================================================================================================================================================================================================================================================\n",
      "A: 0     1.0\n",
      "1     5.5\n",
      "2    10.0\n",
      "Name: A, dtype: float64\n",
      "========================================================================================================================================================================================================================================================================================\n",
      "B: 0    2.0\n",
      "1     34\n",
      "2    NaN\n",
      "Name: B, dtype: object\n",
      "========================================================================================================================================================================================================================================================================================\n",
      "C: 0     NaN\n",
      "1     3.4\n",
      "2    11.5\n",
      "Name: C, dtype: object\n",
      "========================================================================================================================================================================================================================================================================================\n",
      "D: 0      4\n",
      "1    NaN\n",
      "2    8.5\n",
      "Name: D, dtype: object\n",
      "mean:\n",
      "A     5.50\n",
      "B    18.00\n",
      "C     7.45\n",
      "D     6.25\n",
      "dtype: float64\n",
      "A    3\n",
      "B    2\n",
      "C    2\n",
      "D    2\n",
      "dtype: int64\n",
      "A    False\n",
      "B     True\n",
      "C     True\n",
      "D     True\n",
      "dtype: bool\n",
      "A    0\n",
      "B    1\n",
      "C    1\n",
      "D    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import  numpy as np\n",
    "from io import  StringIO\n",
    "csv_data='''\n",
    "A,B,C,D\n",
    "1.0,2.0,x,4\n",
    "5.5,34,3.4,x\n",
    "10,x,11.5,8.5\n",
    "'''\n",
    "data3=pd.read_csv(StringIO(csv_data))\n",
    "print(data3)\n",
    "data3=data3.replace('x',np.NaN)\n",
    "print(data3)\n",
    "for x in data3:\n",
    "    # print(\"====\"*70)\n",
    "    # print(f\"{x}:\",data3[x])\n",
    "    if data3[x].dtype=='object':\n",
    "        data3[x]=data3[x].astype('float64')\n",
    "print(\"mean:\")        \n",
    "print(data3.mean())\n",
    "print(data3.count())\n",
    "print(data3.isnull().any())\n",
    "print(data3.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 丟棄遺失值\n",
    "+ 您可以使用 dropna 方法再搭配 axis 參數方式進行搭配。\n",
    "+ 默認情況下，預設為 axis = 0，也就是會沿著 Rows 進行，當發現到任何值為 NA 就會整個 Row 刪除。\n",
    "+ 若加入參數 how=‘all’ 代表整個 Row 資料都是遺失值情況下才可以刪除丟棄。\n",
    "+ 加入參數 thresh=N 代表刪除包含少於 N 個觀察值的 row。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A     B     C    D   E\n",
      "0   2.0   3.0   4.0  5.0 NaN\n",
      "1   6.0  34.0   6.0  NaN NaN\n",
      "2  10.0   NaN  11.0  8.0 NaN\n",
      "3   NaN   NaN   NaN  NaN NaN\n",
      "4   3.0   NaN   3.0  NaN NaN\n",
      "5   NaN   5.0   NaN  NaN NaN\n",
      "沿著row進行刪除，只要有遺失值就刪除\n",
      "Empty DataFrame\n",
      "Columns: [A, B, C, D, E]\n",
      "Index: []\n",
      "沿著column進行刪除，只要有遺失值就刪除\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4, 5]\n",
      "      A     B     C    D   E\n",
      "0   2.0   3.0   4.0  5.0 NaN\n",
      "1   6.0  34.0   6.0  NaN NaN\n",
      "2  10.0   NaN  11.0  8.0 NaN\n",
      "4   3.0   NaN   3.0  NaN NaN\n",
      "5   NaN   5.0   NaN  NaN NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import  numpy as np\n",
    "from io import  StringIO\n",
    "csv_data='''\n",
    "A,B,C,D,E\n",
    "2,3,4,5,\n",
    "6,34,6,\n",
    "10,,11,8,\n",
    ",,,\n",
    "3,,3,,\n",
    ",5,,,\n",
    "'''\n",
    "drop=pd.read_csv(StringIO(csv_data))\n",
    "print(drop)\n",
    "print('沿著row進行刪除，只要有遺失值就刪除')\n",
    "drop1=drop.dropna(axis=0)#只要一個Row是Nan就移除\n",
    "print(drop1)\n",
    "\n",
    "print('沿著column進行刪除，只要有遺失值就刪除')\n",
    "drop2=drop.dropna(axis=1)#因為每一欄都有NaN所以沒資料\n",
    "print(drop2)\n",
    "\n",
    "drop3=drop.dropna(axis=0,how='all')# 所有都是Nan才移除\n",
    "print(drop3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A     B     C    D   E\n",
      "0   2.0   3.0   4.0  5.0 NaN\n",
      "1   6.0  34.0   6.0  NaN NaN\n",
      "2  10.0   NaN  11.0  8.0 NaN\n",
      "3   NaN   NaN   NaN  NaN NaN\n",
      "4   3.0   NaN   3.0  NaN NaN\n",
      "5   NaN   5.0   NaN  NaN NaN\n",
      "==================================\n",
      "      A     B     C    D   E\n",
      "0   2.0   3.0   4.0  5.0 NaN\n",
      "1   6.0  34.0   6.0  NaN NaN\n",
      "2  10.0   NaN  11.0  8.0 NaN\n",
      "      A     C\n",
      "0   2.0   4.0\n",
      "1   6.0   6.0\n",
      "2  10.0  11.0\n",
      "3   NaN   NaN\n",
      "4   3.0   3.0\n",
      "5   NaN   NaN\n",
      "==================================\n",
      "      A    B     C    D   E\n",
      "0   2.0  3.0   4.0  5.0 NaN\n",
      "2  10.0  NaN  11.0  8.0 NaN\n",
      "      A    B     C    D   E\n",
      "0   2.0  3.0   4.0  5.0 NaN\n",
      "2  10.0  NaN  11.0  8.0 NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import  numpy as np\n",
    "from io import  StringIO\n",
    "csv_data='''\n",
    "A,B,C,D,E\n",
    "2,3,4,5,\n",
    "6,34,6,\n",
    "10,,11,8,\n",
    ",,,\n",
    "3,,3,,\n",
    ",5,,,\n",
    "'''\n",
    "drop=pd.read_csv(StringIO(csv_data))\n",
    "print(drop)\n",
    "print(\"==================================\")\n",
    "drop4=drop.dropna(thresh=3)#非缺失值(有數值的)<thresh移除\n",
    "print(drop4)\n",
    "drop5=drop.dropna(axis=1,thresh=4)#非缺失值(有數值的)<thresh移除\n",
    "print(drop5)\n",
    "print(\"==================================\")\n",
    "drop5=drop.dropna(subset=['C','D'])# c跟d欄位都不是NaN的顯示\n",
    "print(drop5)\n",
    "drop.dropna(subset=['C','D'],inplace=True)# c跟d欄位都不是NaN的顯示\n",
    "print(drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 填充遺失值\n",
    "+ 可使用 fillna 函數進行填充\n",
    "  + 輸入要填充的數值\n",
    "    + 補上中位數：建議補上中位數而非平均值，這樣相對來說不會受到極端值的影響。\n",
    "    + 根據原本的資料分布補上亂數。\n",
    "+ 以下兩種方式可以向後或者向前進行填充\n",
    "   + pad/ffill          代表向後填充\n",
    "   + bfill/backfill   代表向前填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A     B     C    D   E\n",
      "0   2.0   3.0   4.0  5.0 NaN\n",
      "1   6.0  34.0   6.0  NaN NaN\n",
      "2  10.0   NaN  11.0  8.0 NaN\n",
      "3   NaN   NaN   NaN  NaN NaN\n",
      "4   3.0   NaN   3.0  NaN NaN\n",
      "5   NaN   5.0   NaN  NaN NaN\n",
      "      A     B     C    D    E\n",
      "0   2.0   3.0   4.0  5.0  0.0\n",
      "1   6.0  34.0   6.0  0.0  0.0\n",
      "2  10.0   0.0  11.0  8.0  0.0\n",
      "3   0.0   0.0   0.0  0.0  0.0\n",
      "4   3.0   0.0   3.0  0.0  0.0\n",
      "5   0.0   5.0   0.0  0.0  0.0\n",
      "      A     B     C    D    E\n",
      "0   2.0   3.0   4.0  5.0  0.0\n",
      "1   6.0  34.0   6.0  0.0  0.0\n",
      "2  10.0   0.0  11.0  8.0  NaN\n",
      "3   0.0   0.0   0.0  0.0  NaN\n",
      "4   3.0   NaN   3.0  NaN  NaN\n",
      "5   0.0   5.0   0.0  NaN  NaN\n",
      "================================\n",
      "      A     B     C    D    E\n",
      "0   2.0   3.0   4.0  5.0  0.0\n",
      "1   6.0  34.0   6.0  0.0  0.0\n",
      "2  10.0   0.0  11.0  8.0  0.0\n",
      "3   0.0   0.0   NaN  NaN  NaN\n",
      "4   3.0   0.0   3.0  0.0  NaN\n",
      "5   0.0   5.0   0.0  NaN  NaN\n",
      "-------3--------\n",
      "      A     B     C    D   E\n",
      "0   2.0   3.0   4.0  5.0 NaN\n",
      "1   6.0  34.0   6.0  5.0 NaN\n",
      "2  10.0  34.0  11.0  8.0 NaN\n",
      "3  10.0  34.0  11.0  8.0 NaN\n",
      "4   3.0  34.0   3.0  8.0 NaN\n",
      "5   3.0   5.0   3.0  8.0 NaN\n",
      "      A     B     C    D   E\n",
      "0   2.0   3.0   4.0  5.0 NaN\n",
      "1   6.0  34.0   6.0  8.0 NaN\n",
      "2  10.0   5.0  11.0  8.0 NaN\n",
      "3   3.0   5.0   3.0  NaN NaN\n",
      "4   3.0   5.0   3.0  NaN NaN\n",
      "5   NaN   5.0   NaN  NaN NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import  numpy as np\n",
    "from io import  StringIO\n",
    "csv_data='''\n",
    "A,B,C,D,E\n",
    "2,3,4,5,\n",
    "6,34,6,\n",
    "10,,11,8,\n",
    ",,,\n",
    "3,,3,,\n",
    ",5,,,\n",
    "'''\n",
    "fill=pd.read_csv(StringIO(csv_data))\n",
    "print(fill)\n",
    "fill_zero = fill.fillna(0)\n",
    "print(fill_zero)\n",
    "#延軸0填 0\n",
    "fill_zero2 = fill.fillna(0,axis=0,limit=2)\n",
    "print(fill_zero2)\n",
    "print(\"================================\")\n",
    "#延軸1填 0\n",
    "fill_zero2 = fill.fillna(0,axis=1,limit=2)\n",
    "print(fill_zero2)\n",
    "\n",
    "print(\"-------3--------\")\n",
    "fill2=fill.ffill()# 如果當前欄位是NaN  向上一筆同欄直到非NaN的值 寫入目前欄位\n",
    "print(fill2)\n",
    "fill3 = fill.bfill()# 如果當前欄位是NaN  向下一筆同欄直到非NaN的值 寫入目前欄位\n",
    "print(fill3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A       4 non-null      float64\n",
      " 1   B       3 non-null      float64\n",
      " 2   C       4 non-null      float64\n",
      " 3   D       2 non-null      float64\n",
      " 4   E       0 non-null      float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 372.0 bytes\n",
      "None\n",
      "A    4.5\n",
      "B    5.0\n",
      "C    5.0\n",
      "D    6.5\n",
      "E    NaN\n",
      "dtype: float64\n",
      "      A     B     C    D   E\n",
      "0   2.0   3.0   4.0  5.0 NaN\n",
      "1   6.0  34.0   6.0  6.5 NaN\n",
      "2  10.0   5.0  11.0  8.0 NaN\n",
      "3   4.5   5.0   5.0  6.5 NaN\n",
      "4   3.0   5.0   3.0  6.5 NaN\n",
      "5   4.5   5.0   5.0  6.5 NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import  numpy as np\n",
    "from io import  StringIO\n",
    "csv_data='''\n",
    "A,B,C,D,E\n",
    "2,3,4,5,\n",
    "6,34,6,\n",
    "10,,11,8,\n",
    ",,,\n",
    "3,,3,,\n",
    ",5,,,\n",
    "'''\n",
    "fill=pd.read_csv(StringIO(csv_data))\n",
    "print(fill.info())\n",
    "\n",
    "fillmean1=fill.median()\n",
    "print(fillmean1)\n",
    "for k in fill:\n",
    "    fill[k].fillna(fillmean1.loc[k],inplace=True)\n",
    "print(fill)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢查重複"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B  C  D\n",
      "0   2   3  5  5\n",
      "1   5   5  5  5\n",
      "2   5   5  5  5\n",
      "3  13  23  5  5\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "dtype: bool\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "dtype: bool\n",
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import  numpy as np\n",
    "from io import  StringIO\n",
    "csv_data='''\n",
    "A,B,C,D\n",
    "2,3,5,5\n",
    "5,5,5,5\n",
    "5,5,5,5\n",
    "13,23,5,5\n",
    "'''\n",
    "df2=pd.read_csv(StringIO(csv_data))\n",
    "print(df2)\n",
    "print(df2.duplicated())\n",
    "print(df2.duplicated(\"A\"))#A欄重複\n",
    "print(df2.duplicated(\"D\"))#D欄重複"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 丟棄重複值的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B  C  D\n",
      "0   5   5  5  5\n",
      "1   2   3  5  5\n",
      "2   5   5  5  5\n",
      "3  13  23  5  5\n",
      "===================================\n",
      "    A   B  C  D\n",
      "1   2   3  5  5\n",
      "2   5   5  5  5\n",
      "3  13  23  5  5\n",
      "===================================\n",
      "    A   B  C  D\n",
      "1   2   3  5  5\n",
      "3  13  23  5  5\n",
      "===================================\n",
      "    A   B  C  D\n",
      "0   5   5  5  5\n",
      "1   2   3  5  5\n",
      "3  13  23  5  5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import  numpy as np\n",
    "from io import  StringIO\n",
    "csv_data='''\n",
    "A,B,C,D\n",
    "5,5,5,5\n",
    "2,3,5,5\n",
    "5,5,5,5\n",
    "13,23,5,5\n",
    "'''\n",
    "df2=pd.read_csv(StringIO(csv_data))\n",
    "print(df2)\n",
    "df3 =  df2.drop_duplicates(keep=\"last\")\n",
    "print(\"===================================\")\n",
    "print(df3)\n",
    "print(\"===================================\")\n",
    "df3 =  df2.drop_duplicates(keep=False)\n",
    "print(df3)\n",
    "print(\"===================================\")\n",
    "df3 =  df2.drop_duplicates()\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B  C  D\n",
      "0   5   5  5  5\n",
      "1   2   3  5  5\n",
      "2   5   5  5  5\n",
      "3  13  23  5  5\n",
      "===========================\n",
      "   A  B  C  D\n",
      "0  5  5  5  5\n",
      "===========================\n",
      "    A   B  C  D\n",
      "3  13  23  5  5\n",
      "===========================\n",
      "Empty DataFrame\n",
      "Columns: [A, B, C, D]\n",
      "Index: []\n",
      "===========================\n",
      "===========================\n",
      "    A   B  C  D\n",
      "0   5   5  5  5\n",
      "1   2   3  5  5\n",
      "3  13  23  5  5\n",
      "===========================\n",
      "    A   B  C  D\n",
      "1   2   3  5  5\n",
      "2   5   5  5  5\n",
      "3  13  23  5  5\n",
      "===========================\n",
      "    A   B  C  D\n",
      "1   2   3  5  5\n",
      "3  13  23  5  5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import  numpy as np\n",
    "from io import  StringIO\n",
    "csv_data='''\n",
    "A,B,C,D\n",
    "5,5,5,5\n",
    "2,3,5,5\n",
    "5,5,5,5\n",
    "13,23,5,5\n",
    "'''\n",
    "df2=pd.read_csv(StringIO(csv_data))\n",
    "print(df2)\n",
    "print(\"===========================\")\n",
    "df3 = df2.drop_duplicates(subset=[\"C\",\"D\"])\n",
    "print(df3)\n",
    "print(\"===========================\")\n",
    "df3 = df2.drop_duplicates(subset=[\"C\",\"D\"],keep=\"last\")\n",
    "print(df3)\n",
    "print(\"===========================\")\n",
    "df3 = df2.drop_duplicates(subset=[\"C\",\"D\"],keep=False)\n",
    "print(df3)\n",
    "print(\"===========================\")\n",
    "print(\"===========================\")\n",
    "df3 = df2.drop_duplicates(subset=[\"A\",\"B\"])\n",
    "print(df3)\n",
    "print(\"===========================\")\n",
    "df3 = df2.drop_duplicates(subset=[\"A\",\"B\"],keep=\"last\")\n",
    "print(df3)\n",
    "print(\"===========================\")\n",
    "df3 = df2.drop_duplicates(subset=[\"A\",\"B\"],keep=False)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pand群組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   company  salary  age\n",
      "0        A      25   38\n",
      "1        C      39   45\n",
      "2        C       6   34\n",
      "3        C      12   43\n",
      "4        C      41   24\n",
      "5        B      29   29\n",
      "6        B      22   26\n",
      "7        C      21   39\n",
      "8        B      26   47\n",
      "9        B      48   18\n",
      "10       A      30   33\n",
      "11       C       9   40\n",
      "12       C      29   45\n",
      "13       A      25   26\n",
      "14       B      13   16\n",
      "15       A      46   22\n",
      "16       B      24   24\n",
      "17       A       6   41\n",
      "18       A      37   40\n",
      "19       A      41   25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "company=[\"A\",\"B\",\"C\"]\n",
    "data1=pd.DataFrame(\n",
    "{\"company\":[company[x] for x in np.random.randint(0,len(company),20)],\n",
    "\"salary\":np.random.randint(5,50,20),\n",
    "\"age\":np.random.randint(15,50,20)}    \n",
    ")\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001DB99E7B4D0>\n",
      "[('A',    company  salary  age\n",
      "0        A      25   38\n",
      "10       A      30   33\n",
      "13       A      25   26\n",
      "15       A      46   22\n",
      "17       A       6   41\n",
      "18       A      37   40\n",
      "19       A      41   25), ('B',    company  salary  age\n",
      "5        B      29   29\n",
      "6        B      22   26\n",
      "8        B      26   47\n",
      "9        B      48   18\n",
      "14       B      13   16\n",
      "16       B      24   24), ('C',    company  salary  age\n",
      "1        C      39   45\n",
      "2        C       6   34\n",
      "3        C      12   43\n",
      "4        C      41   24\n",
      "7        C      21   39\n",
      "11       C       9   40\n",
      "12       C      29   45)]\n",
      "==========sum==========\n",
      "         salary  age\n",
      "company             \n",
      "A           210  225\n",
      "B           162  160\n",
      "C           157  270\n",
      "==========mean==========\n",
      "            salary        age\n",
      "company                      \n",
      "A        30.000000  32.142857\n",
      "B        27.000000  26.666667\n",
      "C        22.428571  38.571429\n",
      "=========max===========\n",
      "         salary  age\n",
      "company             \n",
      "A            46   41\n",
      "B            48   47\n",
      "C            41   45\n",
      "=========min===========\n",
      "         salary  age\n",
      "company             \n",
      "A             6   22\n",
      "B            13   16\n",
      "C             6   24\n",
      "====================\n",
      "            salary        age\n",
      "company                      \n",
      "A        13.241349   7.819390\n",
      "B        11.627553  11.093542\n",
      "C        14.281190   7.502381\n"
     ]
    }
   ],
   "source": [
    "group = data1.groupby(\"company\")\n",
    "print(group)\n",
    "\n",
    "print(list(group))\n",
    "print(\"==========sum==========\")\n",
    "print(group.sum())\n",
    "print(\"==========mean==========\")\n",
    "print(group.mean())\n",
    "print(\"=========max===========\")\n",
    "print(group.max())\n",
    "print(\"=========min===========\")\n",
    "print(group.min())\n",
    "print(\"====================\")\n",
    "print(group.std())\n",
    "\n",
    "#print(group.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
